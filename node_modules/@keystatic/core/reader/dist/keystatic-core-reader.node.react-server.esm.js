import 'react/jsx-runtime';
import { q as getEntryDataFilepath, P as getValueAtPropPath, y as getCollectionFormat, f as getCollectionPath, o as object, z as getSlugGlobForCollection, B as getDataFileExtension, E as getSingletonFormat, a as getSingletonPath, A as getCollectionItemPath } from '../../dist/index-cd5679e3.node.react-server.esm.js';
import '@sindresorhus/slugify';
import '@braintree/sanitize-url';
import fs from 'fs/promises';
import path from 'path';
import { l as loadDataFile, p as parseProps, f as formatFormDataError } from '../../dist/required-files-4d510aad.node.react-server.esm.js';
import * as React from 'react';
import '@markdoc/markdoc';
import 'slate';
import 'emery/assertions';
import 'emery';
import 'js-base64';
import 'crypto';
import '../../dist/empty-field-ui-5b08ee07.node.react-server.esm.js';
import '@emotion/weak-memoize';
import 'js-yaml';

function cache$1(func) {
  return func;
}

// we conditionally using it since it's not actually in stable react releases yet
// (though it should be unnecessary since this file is only imported in react-server environments anyway)
// it's a function because some tools try to be smart with accessing things on namespace imports
// and error at build time if you try to read an export that doesn't exist on a namespace object
function getCache(react) {
  var _react$cache;
  return (_react$cache = react.cache) !== null && _react$cache !== void 0 ? _react$cache : cache$1;
}
const cache = getCache(React);

async function getAllEntries(root, prefix) {
  return (await Promise.all((await fs.readdir(path.join(root, prefix), {
    withFileTypes: true
  }).catch(err => {
    if (err.code === 'ENOENT') {
      return [];
    }
    throw err;
  })).map(async dirent => {
    const name = `${prefix}${dirent.name}`;
    const entry = {
      entry: dirent,
      name
    };
    if (dirent.isDirectory()) {
      return [entry, ...(await getAllEntries(root, `${name}/`))];
    }
    if (dirent.isFile()) {
      return entry;
    }
    return [];
  }))).flat();
}
const listCollection = cache(async function listCollection(repoPath, collectionPath, glob, formatInfo, extension) {
  const entries = glob === '*' ? (await fs.readdir(path.join(repoPath, collectionPath), {
    withFileTypes: true
  }).catch(err => {
    if (err.code === 'ENOENT') {
      return [];
    }
    throw err;
  })).map(x => ({
    entry: x,
    name: x.name
  })) : await getAllEntries(path.join(repoPath, collectionPath), '');
  return (await Promise.all(entries.map(async x => {
    if (formatInfo.dataLocation === 'index') {
      if (!x.entry.isDirectory()) return [];
      try {
        await fs.stat(path.join(repoPath, getEntryDataFilepath(`${collectionPath}/${x.name}`, formatInfo)));
        return [x.name];
      } catch (err) {
        if (err.code === 'ENOENT') {
          return [];
        }
        throw err;
      }
    } else {
      if (!x.entry.isFile() || !x.name.endsWith(extension)) return [];
      return [x.name.slice(0, -extension.length)];
    }
  }))).flat();
});
function collectionReader(repoPath, collection, config) {
  const formatInfo = getCollectionFormat(config, collection);
  const collectionPath = getCollectionPath(config, collection);
  const collectionConfig = config.collections[collection];
  const schema = object(collectionConfig.schema);
  const glob = getSlugGlobForCollection(config, collection);
  const extension = getDataFileExtension(formatInfo);
  const read = (slug, ...args) => {
    var _args$;
    return readItem(schema, formatInfo, getCollectionItemPath(config, collection, slug), repoPath, (_args$ = args[0]) === null || _args$ === void 0 ? void 0 : _args$.resolveLinkedFiles, `"${slug}" in collection "${collection}"`, slug, collectionConfig.slugField, glob);
  };
  const list = () => listCollection(repoPath, collectionPath, glob, formatInfo, extension);
  return {
    read,
    readOrThrow: async (...args) => {
      const entry = await read(...args);
      if (entry === null) {
        throw new Error(`Entry "${args[0]}" not found in collection "${collection}"`);
      }
      return entry;
    },
    // TODO: this could drop the fs.stat call that list does for each item
    // since we just immediately read it
    all: async (...args) => {
      const slugs = await list();
      return (await Promise.all(slugs.map(async slug => {
        const entry = await read(slug, args[0]);
        if (entry === null) return [];
        return [{
          slug,
          entry
        }];
      }))).flat();
    },
    list
  };
}
const readItem = cache(async function readItem(rootSchema, formatInfo, itemDir, repoPath, resolveLinkedFiles, debugReference, ...slugInfo) {
  let dataFile;
  try {
    dataFile = await fs.readFile(path.resolve(repoPath, getEntryDataFilepath(itemDir, formatInfo)));
  } catch (err) {
    if (err.code === 'ENOENT') {
      return null;
    }
    throw err;
  }
  const {
    loaded,
    extraFakeFile
  } = loadDataFile(dataFile, formatInfo);
  const contentFieldPathsToEagerlyResolve = resolveLinkedFiles ? [] : undefined;
  let validated;
  try {
    validated = parseProps(rootSchema, loaded, [], [], (schema, value, path$1, pathWithArrayFieldSlugs) => {
      if (schema.formKind === 'asset') {
        return schema.reader.parse(value);
      }
      if (schema.formKind === 'content') {
        contentFieldPathsToEagerlyResolve === null || contentFieldPathsToEagerlyResolve === void 0 || contentFieldPathsToEagerlyResolve.push(path$1);
        return async () => {
          let content;
          const filename = pathWithArrayFieldSlugs.join('/') + schema.contentExtension;
          if (filename === (extraFakeFile === null || extraFakeFile === void 0 ? void 0 : extraFakeFile.path)) {
            content = extraFakeFile.contents;
          } else {
            content = await fs.readFile(path.resolve(repoPath, `${itemDir}/${filename}`)).catch(x => {
              if (x.code === 'ENOENT') return undefined;
              throw x;
            });
          }
          return schema.reader.parse(value, {
            content
          });
        };
      }
      if (path$1.length === 1 && slugInfo[0] !== undefined) {
        const [slug, slugField, glob] = slugInfo;
        if (path$1[0] === slugField) {
          if (schema.formKind !== 'slug') {
            throw new Error(`Slug field ${slugInfo[1]} is not a slug field`);
          }
          return schema.reader.parseWithSlug(value, {
            slug,
            glob
          });
        }
      }
      return schema.reader.parse(value);
    }, true);
    if (contentFieldPathsToEagerlyResolve !== null && contentFieldPathsToEagerlyResolve !== void 0 && contentFieldPathsToEagerlyResolve.length) {
      await Promise.all(contentFieldPathsToEagerlyResolve.map(async path => {
        const parentValue = getValueAtPropPath(validated, path.slice(0, -1));
        const keyOnParent = path[path.length - 1];
        const originalValue = parentValue[keyOnParent];
        parentValue[keyOnParent] = await originalValue();
      }));
    }
  } catch (err) {
    const formatted = formatFormDataError(err);
    throw new Error(`Invalid data for ${debugReference}:\n${formatted}`);
  }
  return validated;
});
function singletonReader(repoPath, singleton, config) {
  const formatInfo = getSingletonFormat(config, singleton);
  const singletonPath = getSingletonPath(config, singleton);
  const schema = object(config.singletons[singleton].schema);
  const read = (...args) => {
    var _args$2;
    return readItem(schema, formatInfo, singletonPath, repoPath, (_args$2 = args[0]) === null || _args$2 === void 0 ? void 0 : _args$2.resolveLinkedFiles, `singleton "${singleton}"`, undefined);
  };
  return {
    read,
    readOrThrow: async (...opts) => {
      const entry = await read(...opts);
      if (entry === null) {
        throw new Error(`Singleton "${singleton}" not found`);
      }
      return entry;
    }
  };
}
function createReader(repoPath, config) {
  return {
    collections: Object.fromEntries(Object.keys(config.collections || {}).map(key => [key, collectionReader(repoPath, key, config)])),
    singletons: Object.fromEntries(Object.keys(config.singletons || {}).map(key => [key, singletonReader(repoPath, key, config)])),
    repoPath,
    config
  };
}

export { createReader };
